{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw1p2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yyrRaK8LtQNt","colab_type":"text"},"source":["**Frame-Level Classification of Speech**\n","\n","Author: Brian Yan\n","\n","Implemented for Kaggle: https://www.kaggle.com/c/11-785-s20-hw1p2/overview\n","\n","References MNIST MLP example provided by Deep Learning Course, CMU."]},{"cell_type":"code","metadata":{"id":"-1hGAYE62iMa","colab_type":"code","colab":{}},"source":["## Run this code to ensure high ram instance in Google Colab\n","\n","# a = []\n","# while(1):\n","#     a.append('1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g40cXhwDbRUm","colab_type":"code","colab":{}},"source":["version = 'm6'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yMgHBWh1Zvlk","colab_type":"text"},"source":["**SETUP**\n","\n","Mounting drive, installing packages, downloading dataset from Kaggle"]},{"cell_type":"code","metadata":{"id":"V2aA2qooW8wI","colab_type":"code","colab":{}},"source":["# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json\n","# !ls ~/.kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOEbwDH2XJzJ","colab_type":"code","colab":{}},"source":["# !ls -l ~/.kaggle\n","# !cat ~/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JITbyIjkXREc","colab_type":"code","colab":{}},"source":["# !pip install -q kaggle\n","# !pip install -q kaggle-cli"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsGkPps8XqLN","colab_type":"code","outputId":"c569c800-2e8d-4a21-ad54-f7abd40cead5","executionInfo":{"status":"ok","timestamp":1581130453069,"user_tz":300,"elapsed":17987,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kpQuc1NiYArV","colab_type":"code","colab":{}},"source":["root_path = '/content/gdrive/My Drive/Frame-Level Classification of Speech/'  #change dir to your project folder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WokUcqz0YWxt","colab_type":"code","colab":{}},"source":["# !kaggle competitions download -c 11-785-s20-hw1p2 -p /content/gdrive/My\\ Drive/Frame-Level\\ Classification\\ of\\ Speech"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1YTIhPHaQav","colab_type":"code","colab":{}},"source":["# import os\n","# os.chdir(root_path)  #change dir\n","# !ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BCmrrTyzZZMB","colab_type":"code","colab":{}},"source":["# !unzip dev_labels.npy.zip\n","# !unzip dev.npy.zip\n","# !unzip test.npy.zip\n","# !unzip train.npy.zip\n","# !unzip hw1p2_sample_submission.csv.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nZX6xBGLaW9D","colab_type":"code","colab":{}},"source":["# !rm dev_labels.npy.zip\n","# !rm dev.npy.zip\n","# !rm test.npy.zip\n","# !rm train.npy.zip\n","# !rm hw1p2_sample_submission.csv.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_SAM4Mn_b2TA","colab_type":"code","colab":{}},"source":["# !unzip train_labels.npy.zip\n","# !rm train_labels.npy.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBYRzwdNcjfz","colab_type":"code","colab":{}},"source":["# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WV5_cIKWdD53","colab_type":"code","colab":{}},"source":["# !pip3 install torchvision"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYljOP3_eqAG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import sys\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils import data\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","\n","import matplotlib.pyplot as plt\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8df8O3K_J20","colab_type":"code","outputId":"00dccbd2-a9ff-4bdc-81ce-43503a361aa8","executionInfo":{"status":"ok","timestamp":1581130456854,"user_tz":300,"elapsed":3664,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cuda = torch.cuda.is_available()\n","cuda"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Bw5VhKqrcT6J","colab_type":"text"},"source":["**DATA LOADER**\n","\n","Custom data loader class. Dataset is composed of frames of audio, and a single frame does not contain enough context for predictions. It is preferrable to use a window of frames in this task. This implementation uses k = 9, for a window size of (2k + 1).  "]},{"cell_type":"code","metadata":{"id":"l6BAuHF_cXuA","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, Dataset, TensorDataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzwRUWvMO11x","colab_type":"code","colab":{}},"source":["train_x = np.load(root_path + \"/train.npy\", allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c0leRXoqQwkw","colab_type":"code","colab":{}},"source":["train_y = np.load(root_path + \"/train_labels.npy\", allow_pickle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXydyekDxyp5","colab_type":"code","colab":{}},"source":["# flatten the frames within each utterance, x_i, so that they can be loaded by Data Loader\n","def flatten_frames(x_list):\n","    indexes = []\n","    for i in range(len(x_list)):              #utterance\n","        for j in range(x_list[i].shape[0]):   #frame\n","            indexes.append((i, j))\n","    return indexes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCgcNpo2eSay","colab_type":"code","colab":{}},"source":["class myDataset(Dataset):\n","    def __init__(self, x, y, k = 9):\n","        self.k = k\n","        self.x = x\n","        self.y = y\n","        self.idx_to_frame = flatten_frames(x)\n","\n","    def __len__(self):\n","        return len(self.idx_to_frame)\n","    \n","    def __getitem__(self, idx):\n","        i, j = self.idx_to_frame[idx]\n","        lo = j - self.k\n","        hi = j + 1 + self.k\n","        x_i = self.x[i].take(range(lo, hi), mode='clip', axis=0)\n","        x_i = torch.from_numpy(x_i).float().reshape(-1)\n","        if self.y is None:\n","            y_i = -1\n","        else:\n","            y_i = self.y[i][j]\n","        return x_i, y_i"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1YR8u63luII","colab_type":"code","colab":{}},"source":["k = 9"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CR-RISFTAZ5","colab_type":"code","colab":{}},"source":["dev_dataset = myDataset(train_x, train_y, k)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hRJdEO8U5Sy","colab_type":"code","colab":{}},"source":["num_workers = 8 if cuda else 0\n","train_loader_args = dict(shuffle=True, batch_size=1024, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=True, batch_size=64)\n","train_loader = data.DataLoader(dev_dataset, **train_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xEy9g7WUAO6c","colab_type":"code","colab":{}},"source":["test_x = np.load(root_path + \"/dev.npy\", allow_pickle=True)\n","test_y = np.load(root_path + \"/dev_labels.npy\", allow_pickle=True)\n","test_dataset = myDataset(test_x, test_y, k)\n","test_loader_args = dict(shuffle=True, batch_size=1000, num_workers=num_workers, pin_memory=True) if cuda\\\n","                    else dict(shuffle=True, batch_size=1000)\n","test_loader = data.DataLoader(test_dataset, **test_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZvrPrGCB52j_","colab_type":"text"},"source":["**MODEL**\n","\n","The implemented MLP is a deep NN with batch normalization and dropout at each hidden layer. Dropout at 10% boosted accuracy on the validation set by 3%, achieving 65+% accuracy.\n","\n","The layer sizes were chosen based on the input size. The first layers are wider to capture more information from the features. The later layers can be more narrow. The depth of the model boosts accuracy."]},{"cell_type":"code","metadata":{"id":"JHzYP8d655Ua","colab_type":"code","colab":{}},"source":["in_size = (2 * k + 1) * 40\n","out_size = 138\n","\n","model = nn.Sequential(\n","                nn.Linear(in_size, in_size*2),\n","                nn.BatchNorm1d(in_size*2),\n","                nn.ReLU(),\n","                nn.Dropout(.1),\n","\n","                nn.Linear(in_size*2, in_size),\n","                nn.BatchNorm1d(in_size),\n","                nn.ReLU(),\n","                nn.Dropout(.1),\n","\n","                nn.Linear(in_size, in_size),\n","                nn.BatchNorm1d(in_size),\n","                nn.ReLU(),\n","                nn.Dropout(.1),\n","\n","                nn.Linear(in_size, in_size // 2),\n","                nn.BatchNorm1d(in_size // 2),\n","                nn.ReLU(),\n","                nn.Dropout(.1),\n","\n","                nn.Linear(in_size // 2, out_size)\n","            )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAQe_-0ZVduE","colab_type":"code","colab":{}},"source":["save_path = root_path + version+ \".pt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hS6HfVxNipXs","colab_type":"code","outputId":"7912abe9-593d-498e-fa53-de572f0f37db","executionInfo":{"status":"ok","timestamp":1581134173875,"user_tz":300,"elapsed":13838,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["model.load_state_dict(torch.load(save_path))"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"code","metadata":{"id":"Dhj6Zgr67LPb","colab_type":"code","outputId":"09c2bff6-e321-45ee-ffb7-4173bb4e1d2c","executionInfo":{"status":"ok","timestamp":1581134173878,"user_tz":300,"elapsed":13381,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":336}},"source":["model.cuda()\n","optimizer = optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","model.to(device)\n","print(model, device)"],"execution_count":92,"outputs":[{"output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=760, out_features=1520, bias=True)\n","  (1): BatchNorm1d(1520, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU()\n","  (3): Dropout(p=0.1, inplace=False)\n","  (4): Linear(in_features=1520, out_features=760, bias=True)\n","  (5): BatchNorm1d(760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (6): ReLU()\n","  (7): Dropout(p=0.1, inplace=False)\n","  (8): Linear(in_features=760, out_features=760, bias=True)\n","  (9): BatchNorm1d(760, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (10): ReLU()\n","  (11): Dropout(p=0.1, inplace=False)\n","  (12): Linear(in_features=760, out_features=380, bias=True)\n","  (13): BatchNorm1d(380, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (14): ReLU()\n","  (15): Dropout(p=0.1, inplace=False)\n","  (16): Linear(in_features=380, out_features=138, bias=True)\n",") cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0tLgwHPFBWvY","colab_type":"code","outputId":"5d80a1e8-213d-43e6-d4c2-19cbe75e3ac1","executionInfo":{"status":"ok","timestamp":1581134175509,"user_tz":300,"elapsed":14812,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":286}},"source":["!nvidia-smi"],"execution_count":93,"outputs":[{"output_type":"stream","text":["Sat Feb  8 03:56:15 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P0    35W / 250W |    889MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wR5RpQAE8MU5","colab_type":"text"},"source":["**Train**"]},{"cell_type":"code","metadata":{"id":"eJiSfaJN8KNF","colab_type":"code","colab":{}},"source":["def train_epoch(model, train_loader, criterion, optimizer):\n","    model.train()\n","\n","    running_loss = 0.0\n","    \n","    start_time = time.time()\n","    for batch_idx, (data, target) in enumerate(train_loader):   \n","        optimizer.zero_grad()   # .backward() accumulates gradients\n","        data = data.to(device)\n","        target = target.to(device) # all data & model on same device\n","\n","        outputs = model(data)\n","        loss = criterion(outputs, target)\n","        running_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","    \n","    end_time = time.time()\n","    \n","    running_loss /= len(train_loader)\n","    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n","    return running_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"egXXRVlz8aRZ","colab_type":"code","colab":{}},"source":["def test_model(model, test_loader, criterion):\n","    with torch.no_grad():\n","        model.eval()\n","\n","        running_loss = 0.0\n","        total_predictions = 0.0\n","        correct_predictions = 0.0\n","\n","        for batch_idx, (data, target) in enumerate(test_loader):   \n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_predictions += target.size(0)\n","            correct_predictions += (predicted == target).sum().item()\n","\n","            loss = criterion(outputs, target).detach()\n","            running_loss += loss.item()\n","\n","\n","        running_loss /= len(test_loader)\n","        acc = (correct_predictions/total_predictions)*100.0\n","        print('Testing Loss: ', running_loss)\n","        print('Testing Accuracy: ', acc, '%')\n","        return running_loss, acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zamQedSR8dj5","colab_type":"code","colab":{}},"source":["n_epochs = 100\n","Train_loss = []\n","Test_loss = []\n","Test_acc = []\n","\n","for i in range(n_epochs):\n","    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n","    # if i % 5 == 0:\n","    test_loss, test_acc = test_model(model, test_loader, criterion)\n","    Train_loss.append(train_loss)\n","    Test_loss.append(test_loss)\n","    Test_acc.append(test_acc)\n","    print('='*20)\n","    torch.save(model.state_dict(), save_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPJ_eG7l9CtB","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), save_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eDTOSPBE7HUx","colab_type":"text"},"source":["**PREDICTIONS**"]},{"cell_type":"code","metadata":{"id":"akSD-Ve87I3F","colab_type":"code","colab":{}},"source":["def predict(model, predict_loader):\n","  with torch.no_grad():\n","        model.eval()\n","\n","        ids = []\n","        preds = []\n","        for batch_idx, (data, target, idx_val) in enumerate(predict_loader):   \n","            data = data.to(device)\n","            target = target.to(device)\n","\n","            outputs = model(data)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","\n","            ids.append(idx_val.cpu().numpy())\n","            preds.append(predicted.cpu().numpy())\n","\n","        return ids, preds"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvnC01-6ARga","colab_type":"code","colab":{}},"source":["pred_x = np.load(root_path + \"/test.npy\", allow_pickle=True)\n","pred_dataset = myDataset(pred_x, None, k)\n","pred_loader_args = dict(shuffle=False, batch_size=1000, num_workers=0, pin_memory=True) if cuda\\\n","                    else dict(shuffle=False, batch_size=1000)\n","pred_loader = data.DataLoader(pred_dataset, **pred_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXdZgU6DAq_q","colab_type":"code","colab":{}},"source":["to_csv = predict(model, pred_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RjpXzo-rBQOk","colab_type":"code","colab":{}},"source":["id_a, pred_a = to_csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5ORUXwcLCz-","colab_type":"code","outputId":"58a7b288-cbad-43f4-b139-7c9d2c2d7604","executionInfo":{"status":"ok","timestamp":1580923949944,"user_tz":300,"elapsed":183288,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(len(id_a), len(pred_a))\n","id_a = [val for sublist in id_a for val in sublist]\n","pred_a = [val for sublist in pred_a for val in sublist]\n","print(len(id_a), len(pred_a))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["224 224\n","223592 223592\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KuhaKIm8JWTl","colab_type":"code","colab":{}},"source":["import csv\n","import operator\n","\n","f = open(root_path + version + '.csv', 'w')\n","\n","with f:\n","    writer = csv.writer(f)\n","    for i in range(len(id_a)):\n","        if i == 0:\n","            writer.writerow(['id', 'label'])\n","        writer.writerow([i, pred_a[i]])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"74s79tLUgh9G","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}